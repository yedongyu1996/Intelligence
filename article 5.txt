 # DeepSeek 和 ChatGPT 双证法及其情报学应用（2025-07-17）

研究对象
研究领域: 情报学、生成式人工智能（GenAI）。
核心对象:
    一种基于“广义二重证据法”理论提出的 GenAI“双证法”框架。
    两个作为异质信源的大语言模型：DeepSeek-r1 和 ChatGPT-03。
数据来源:
    一个包含 110 条任务的情报领域自建数据集，该数据集覆盖情报工作的“收集—分析—预见”全流程，包含结构化、半结构化与自由文本等多种生成形式。

研究方法
理论基础：广义二重证据法
    用途: 为使用两个异质大语言模型进行交叉验证提供方法论支撑。
    前提: 该理论认为，若针对同一问题，通过两种不同来源的证据或两种不同方法能得到相同或统一的结论，则该结论具有较高的可信度。研究将其应用于 GenAI 领域，将两个独立的 LLM 视作两种不同的“证据”来源。
实验框架：GenAI“双证法”
    用途: 评估并提升大模型在情报分析任务中的可靠性，解决单模型依赖带来的技术幻觉和可解释性缺失等问题。
    设计:
        并行推理: 将同一情报任务指令，在隔离环境中分别输入 DeepSeek-r1 和 ChatGPT-03。
        交叉验证: 从形式、语义、逻辑三个维度，对两个模型的输出结果进行量化一致性比对。
量化评估指标
    用途: 客观、可重复地衡量两个模型生成文本的一致性。
    具体指标:
        形式一致性:
            BLEU-4: 评估词汇片段的重叠度。
            ROUGE-L: 基于最长公共子序列评估句法结构的相似度。
            Jaccard: 衡量关键词集合的相似性。
        语义一致性:
            BERTScore: 利用词向量计算文本在意义表达上的相似度。
        逻辑一致性:
            Cross-NLI: 通过自然语言推理判断两个文本间的蕴含、矛盾或中立关系。
    计算策略: 采用“双向对称”计算，即轮流将一个模型的输出作为另一模型的参考文本，再取平均分，以消除偏差。
人工核验机制
    用途: 针对数值型、代码型等评估指标可能失真的结构化文本，进行正确性和一致性的最终确认。
    标准: 对于数值型任务，以官方数据为基准，偏差小于 5% 视为部分不一致，大于等于 5% 视为完全不一致；对于代码和 URL，通过运行测试其功能一致性。

研究出发点与创新性
背景与动机:
    信噪比下降: GenAI 降低了内容生产门槛，导致虚假和冗余信息激增，传统“人工+规则”的过滤机制失效。
    时效性要求: 动态情报环境要求快速反应，但 LLM 的推理可靠性成为瓶颈。
    单源依赖风险: 单独依赖一个 LLM 会面临“技术幻觉”（生成看似合理但事实错误的内容）和结果不可验证的风险，这与情报工作要求的严谨性相悖。
创新点:
    方法论引入: 首次将历史学领域的“广义二重证据法”引入 GenAI 时代的情报学研究，提出了一套“异质模型并行互证”的可操作框架，为解决 LLM 的幻觉和单源依赖问题提供了新路径。
    实证验证: 通过对 DeepSeek-r1 和 ChatGPT-03 这两个在技术架构与训练语料上存在显著差异的 LLM 进行实证对比，验证了“双证法”在真实情报任务场景下的客观可行性。
    多维评估体系: 构建了一个从形式、语义到逻辑的多维度量化评估体系来检验模型输出的一致性，超越了传统上对单一正确答案的评估模式。

详细研究内容
4.0 引言与研究现状
生成式 AI 已深度渗透到情报工作的各个环节，但其“黑箱”特性、技术幻觉和单源依赖问题，与情报工作要求的客观严谨性产生矛盾。
当前情报工作面临三大困境：信息过载导致信噪比下降；动态情报感知对时效性和准确性提出更高要求；单一模型分析存在技术幻觉与可解释性危机。为应对这些挑战，研究引入“双证法”思想。

4.2 理论基础与研究设计
理论溯源: “双证法”源于王国维通过“地下之新出土品”与“纸上之旧文献”相互印证的研究方法，后被叶鹰等人推广为“广义二重证据法”。本文将其应用于 GenAI，认为若两个独立的 LLM 对同一任务得出相似结论，可视为一次有效的“二重证据”检验。
研究思路: 采用四步法：构建覆盖情报全链条的任务数据集；将任务分别输入两个异质模型；对输出文本进行标准化处理；从形式、语义、逻辑三维度量化比对。
模型选择: 选用 DeepSeek-r1 和 ChatGPT-03，主要基于三点考虑：技术架构的独立性（前者为 MoE 架构，后者为密集 Transformer）；推理范式的互补性（前者为自我反思，后者依赖思维链）；对中文情报任务的适应性。
数据集构建: 构建了含 110 条指令的数据集，划分为情报收集、情报分析和情报预见三大类，共 22 项子任务，每项设置 5 道问题，兼顾中英文与不同输出形式（文本、数值、代码等）。
提示词设计: 所有指令采用“角色—任务—格式”（RTF）的规范化结构，并为每项任务设计了两轮提示词，第二轮在第一轮基础上进行优化。

4.3 实证研究
整体结果: 经过第二轮提示词优化后，两个模型输出的一致性得分在所有指标上均有提升。形式一致性指标（Bleu-4, Jaccard, Rouge-L）增幅显著（60.37%, 34.69%, 28.50%），而语义和逻辑一致性指标（BertScore, Cross-NLI）基数较高，增幅平稳。这表明精细化的提示词能有效促使模型对任务的理解趋同。
不同任务对比:
    情报收集: 在关系抽取、实体识别等结构化任务上一致性极高（BERTScore 0.91），但在热点信息检索、设计问卷等开放性任务上一致性较差。
    情报分析: 在主题领域分类任务上一致性达到完美（所有指标为 1.0）。文本摘要等半结构化任务一致性较高，而开放的文本生成任务则形式差异大，但语义层面仍保持稳定。
    情报预见: 该类别任务（如决策建议、风险评估）的一致性得分普遍最低，反映了其高度复杂性和不确定性。
不同文本类型对比:
    结构化（URL, JSON 等）和半结构化文本（摘要、分类）的一致性远高于自由文本。尤其在语义和逻辑层面，前两者表现出很强的一致性。
结构化文本人工核验:
    在 30 条结构化任务中，14 条结果完全一致，11 条不完全一致，5 条完全不一致。
    案例分析发现，在获取 GDP 数据等数值检索任务中，DeepSeek 的结果比 ChatGPT 更准确；但在词频统计任务中，ChatGPT 的结果更为正确，表明两者各有优劣。

4.4 应用讨论
研究证实了“双证法”的实际应用价值，尤其是在目标明确、输出结构化程度高的任务中，可显著提升效率。对于开放性任务，两个模型的输出可互为参照，或引入专家复核。
提出应用框架:
    将情报任务指令同时输入 ChatGPT 和 DeepSeek。
    对输出进行一致性校验。
    若通过，则由人工最终确认后输出结果。
    若不通过，则转交专家进行复核。
设想了三个典型应用场景:
    情报信息智能筛选: 以一致性得分作为信息可信度的初步判断依据。
    情报分析交叉印证: 将一致的结论作为强支撑，对不一致的结论，要求模型提供理由，辅助分析师聚焦分歧点。
    情报预见与风险预警: 将双模型共同识别的信号视为高置信度预警，有效降低误报和漏报率。

4.5 结论与展望
主要结论:
    方法论上，成功将“异质模型并行互证”的模式引入情报学，为应对 AI 幻觉等问题提供了技术路径。
    实践上，通过对 DeepSeek-r1 和 ChatGPT-03 的实证研究，验证了该“双证法”框架在情报工作中的可行性。
局限性:
    “一致”不完全等同于“正确”，当两个模型基于相似的缺陷语料做出同样错误的推断时，该方法会失效，仍需外部事实校准。
    实验仅限于文本单模态，未覆盖图像、音频等多模态情报。
未来展望:
    多模型交叉佐证是情报学迈向“可信智能”的关键。本文提出的“双证法”有望在未来的情报研究与实践中发挥更大作用，为情报工作提供更稳健、透明的智能支撑。

研究结论
核心结论:
    本文提出的 GenAI“双证法”在情报学领域具有实际应用价值。在高结构化任务（如关系抽取、实体识别、主题分类）中，DeepSeek-r1 与 ChatGPT-03 的输出一致性表现突出，可显著提升情报处理效率。
    精细化的多轮提示词优化，能够有效促使不同模型对任务的理解和回应在语义、逻辑等层面趋同，从而增强情报分析的整体可信度。
    在数值型和事实检索类任务中，不同模型各有优劣，交叉验证能够有效发现单一模型的错误。
实践意义:
    提出了一个具体可行的操作框架，情报人员可通过并行调用两个异质模型，对结果进行一致性检验，若结果一致则采信，若不一致则启动专家复核，以此规避单一模型的知识盲区和逻辑偏差。
    该方法可应用于情报筛选、分析挖掘和风险预警等多个环节，提升情报产品的可靠性与决策支撑效能。
未来工作:
    需要探索引入外部知识库或事实核查工具的机制，解决“一致但错误”的潜在问题。
    应将“双证法”的验证范围从文本模态扩展至图像、音频等多模态情报分析领域。