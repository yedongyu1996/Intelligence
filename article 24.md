 # 面向美国国会听证会的中国科技安全风险智能化识别——基于大语言模型等技术 (2025-04-22)

## 1. 研究对象
- **研究领域**: 国家科技安全情报分析、大语言模型应用。
- **核心对象**: 美国国会听证会文本中，与中国科技安全相关的风险情报。
- **数据来源**:
  - **主要数据**: 美国政府信息公开网站 (govinfo.gov) 公布的第118届国会听证会文本。
  - **具体案例**: 选取了与中国关系密切的8个委员会（4个众议院、3个参议院、1个联席）的63场听证会，共计143,041句话作为实验语料。

## 2. 研究方法
- **智能化识别框架**: 作者构建了一个由三个核心模块组成的智能化分析流程，旨在从海量、非结构化的听证会文本中高效识别中国科技安全风险。
  - **细粒度文本过滤模块**:
    - **用途**: 从庞杂的听证会全文中筛选出与“中国科技”主题强相关的句子，解决信息稀疏问题。
    - **算法/模型**: 采用大语言模型 (LLM) 进行两阶段过滤。首先在段落级别进行初步筛选，然后在句子级别结合段落上下文进行精准判断。通过向LLM提问并分析其对“Yes”/“No”的输出概率来完成分类。
    - **前提条件**: 假设LLM的概率输出可以有效反映文本相关性。
  - **摘要生成模块**:
    - **用途**: 基于过滤后的相关文本，生成面向中国科技安全主题的、可循证的听证会摘要。
    - **算法/模型**: 利用大语言模型根据预设的提示词 (Prompt) 生成摘要内容和支撑证据。引入了事实核查机制，使用 Levenshtein Ratio 相似度算法计算模型输出的证据与原文句子的匹配度，以保证摘要的可信度。
    - **关键参数**: Levenshtein Ratio 用于量化证据与原文的相似性。
  - **智能问答模块**:
    - **用途**: 实现跨听证会文档的、有深度的主题问答，并能进行风险点识别和政策预测。
    - **算法/模型**:
      1.  **知识图谱构建**: 通过主题模型 (LDA, TextRank) 提取摘要关键词作为主题，并利用 NetworkX 和 Gephi 构建主题-听证会共现图谱。
      2.  **检索策略**: 结合用户查询的主题、共现图谱中的关联主题以及预先提取的科技安全风险要素（项目、人员、机构等），召回相关的听证会文本片段。
      3.  **回答生成**: 利用大语言模型基于检索到的材料生成回答，并采用与摘要生成模块相同的 Levenshtein Ratio 机制进行证据核查。
    - **实验模型**: 实验主要采用 OpenAI 的 GPT-4o 和 GPT-4o-mini 模型，温度参数设为0以确保结果的稳定性。

## 3. 研究出发点与创新性
- **背景与动机**:
  - **现实需求**: 在中美科技竞争加剧的背景下，美国国会听证会成为洞察其对华科技政策动向和立法意图的关键情报来源。
  - **分析难点**: 听证会文本具有“数量大”（每届国会约3.5亿单词）、“范围广”（涵盖政治、军事、商业等）、“口语化”（非正式表达、俚语、缩写多）的特点，传统文本分析方法和人工分析均难以胜任。
  - **现有技术局限**: 虽然大语言模型 (LLM) 潜力巨大，但现有方法在处理此类信息极度稀疏的长文本时表现不佳，且存在“幻觉”风险，缺乏可循证性，难以进行有效的跨文档关联分析。
- **创新点**:
  1.  **提出完整框架**: 构建了一套集“文本过滤-摘要生成-智能问答”于一体的、专门面向国会听证会场景的智能化风险识别流程。
  2.  **解决信息稀疏问题**: 设计了一种基于LLM的两阶段（段落-句子）细粒度文本过滤方法，有效从海量无关内容中定位关键信息。
  3.  **确保结果可循证**: 在摘要生成和智能问答模块中，创新性地引入了证据与原文的匹配度计算机制 (Levenshtein Ratio)，显著提升了分析结果的透明度和可靠性。
  4.  **实现跨文档关联分析**: 通过构建主题共现图谱，实现了对分散在多场听证会中相关议题的有效关联和检索，为深度问答提供了基础。

## 4. 详细研究内容
### 4.1 引言 (Introduction)
- 文章指出，美国国会听证会是其立法程序的关键环节，直接影响对华科技法案的形成。因此，分析听证会内容对挖掘科技安全风险情报至关重要。
- 分析面临三大挑战：文本量巨大、主题广泛、语言口语化且复杂。
- 现有大语言模型应用存在不足：在信息稀疏的长文本中表现不佳、可循证性差、缺乏跨文档分析能力。
- 本文提出一个包含文本过滤、摘要生成、智能问答三大模块的智能化方法框架，旨在解决上述难题，并强调了方法的可循证性。

### 4.2 国内外研究现状 (Related Work)
- **面向我国科技安全风险的分析研究**:
  - 梳理了国内在科技安全风险领域的现有研究，主要分为分析框架构建、机制梳理和案例分析三类。
  - 本文在此基础上，归纳了项目、人员、机构、经费、设备等一系列具体的科技安全风险要素，并将其融入到识别方法中。
- **基于大语言模型的文本分析技术**:
  - 回顾了从传统的“预训练+微调”（如BERT）到当前流行的“零/少样本提示”（如ChatGPT）的技术演进。
  - 提到了检索增强生成 (RAG) 技术能结合外部知识库提升准确性。
  - 再次强调现有方法无法直接应用于本研究场景，因为它们难以处理长对话文本中的稀疏信息，且通常针对单篇文本，可循证能力弱。

### 4.3 方法框架 (Method Framework)
- 框架整体流程图如图1所示，由细粒度文本过滤、摘要生成和智能问答三个模块串联而成。
- **细粒度文本过滤**:
  - 输入原始听证会数据，通过LLM进行段落和句子的两级筛选，找出与中国科技相关的句子，并进一步提取其中包含的科技安全风险要素。
- **摘要生成**:
  - 输入过滤后的相关句子及其上下文，利用LLM生成摘要，并通过事实核查机制（Levenshtein Ratio）验证证据与原文的匹配度，产出可信的听证会摘要。
- **智能问答**:
  - 预先对所有摘要进行主题建模，构建听证会主题共现图谱。
  - 当用户提问时，根据问题、图谱和要素表召回相关文本，再由LLM生成附带可验证证据的答案。
- **数学符号与公式**:
  - 定义了文档、段落、句子的层级结构：$D=\{d_i\}, d_i=[p_i^j], p_i^j=[s_i^j(k)]$。
  - 过滤过程基于LLM的概率输出：$P_{para}(y)=LLM_{prob}(Prompt_{para})$。
  - 摘要和问答生成：$Response=LLM(Prompt)$。
  - 证据核查通过正则表达式提取证据 $Evids=Match(Response)$，并计算其与原文最佳匹配句子的 Levenshtein Ratio：$Score(e_l) = lev\_ratio(s_l, e_l)$。
  - 问答中的文本召回利用了主题图谱的邻居节点查找：$T_q^K=Neighbor_G(T_q,K)$。

### 4.4 实验 (Experiments)
- **实验数据与配置**:
  - 数据集：63场第118届国会听证会，143,041句话被人工标注。
  - 模型：GPT-4o 和 GPT-4o-mini，温度为0。
- **细粒度文本过滤实验**:
  - **基线方法**: 关键词匹配、模糊匹配、向量匹配 (Sentence-BERT)。
  - **结果**: 本文方法 (Ours) 在所有委员会数据上均取得最高的F1值（GPT-4o综合F1为0.7751），显著优于所有基线。LLM能够理解缩写（如EV）和俚语（如be below the radar），而其他方法不能。
- **摘要生成实验**:
  - **基线方法**: 标准提示 (Standard Prompting, SP)，即直接将全文喂给LLM。
  - **结果**:
    - 在ROUGE指标上，本文方法全面优于SP方法，尤其在信息稀疏场景下优势更明显 (图2)。
    - 在证据可靠性上，本文方法生成的证据与原文的匹配度得分显著高于SP方法，分布更集中于0.95-1.0区间 (图3)。
    - **案例分析**: 在一个包含10万词但仅有7句相关内容的听证会中，本文方法准确总结了与中国电动汽车相关的风险，而SP方法则偏离主题，未能抓住关键信息 (表5)。
- **智能问答实验**:
  - **基线方法**: 标准提示 (SP) 和 原版检索增强生成 (RAG)。
  - **任务1：风险点识别**:
    - **结果**: 在10个预设问题上，本文方法的风险点召回率达到0.7636，远高于SP (0.4545) 和RAG (0.2727) (表7)。
  - **任务2：新法案通过可能性预测与循证**:
    - **结果**: 针对11项新法案，本文方法的预测准确率 (0.9091) 和证据可靠率 (0.9356) 均为最高 (表9)。RAG因检索模块不佳而表现最差。
  - **案例分析**:
    - 展示了构建的主题共现图谱 (图4)，揭示了议题间的关联。
    - 在回答“哪些公司与数据安全相关”的问题时，SP回答笼统，RAG仅找到TikTok，而本文方法识别出多家在听证会中被提及的公司，包括华为、海康威视、安途、小马智行等 (图5)。
    - 展示了利用思维链提示进行深度推理分析的能力，系统能从中国的立场分析数据安全议题，并列出可能的风险和应对措施 (表10)。

## 5. 研究结论
- **主要结论**:
  1.  本文提出的基于大语言模型的智能化识别框架，能够有效应对美国国会听证会文本量大、信息稀疏、语言复杂的挑战。
  2.  该方法具备三大核心优势：对稀疏信息的**高度敏感性**，对俚语和缩写的**强大语义识别能力**，以及通过证据匹配机制实现的**结果可循证性**。
  3.  实验证明，该方法在文本过滤、摘要生成和智能问答任务上均显著优于基线方法，展现了其在科技安全情报分析领域的实用价值和潜力。
- **实践意义**:
  - 该方法能够辅助情报分析人员深入、高效地挖掘美国国会科技情报，为我国制定科技安全应对策略提供决策支持。
- **未来工作**:
  - 未来的研究将致力于针对更多样化的任务和更新的大语言模型，设计更为通用和高效的信息提取机制。