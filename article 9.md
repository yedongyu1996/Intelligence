 # 对数智赋能情报工作的反思（2025-06-10）

## 1. 研究对象
- **研究领域**: 情报学理论与方法、数智技术应用。
- **核心对象**: 数智技术（特指以生成式人工智能为代表的大模型）赋能情报工作的有效性、应用边界及内在风险。文章从情报学的根本定义出发，对技术与情报工作的关系进行批判性反思。
- **案例来源**: 本文为理论性探讨，未依赖特定数据集，而是通过概念辨析和思想实验进行论证，辅以普适性案例说明观点（如道路拥堵预测、学生作息时间分析等）。

## 2. 研究方法
- **方法论**: 主要采用思辨与阐释的研究方法，立足于情报学的基本内涵与核心价值。
    - **用途**: 通过对数智赋能情报工作的依据、可信性、底层数据和观点生成逻辑等四个层面进行逐一反思，旨在辨析技术的角色，明确其在情报工作中的应用边界。
    - **前提假设**: 文章提出，情报的定义应当是稳定且成熟的，不应随技术或应用领域的改变而随意变化。作者基于此提出一个工作定义：“情报是人脑做出的有价值的判断”，其核心是“判读”过程，并以此作为全文的评判基准。

## 3. 研究出发点与创新性
- **背景与动机**:
    - 当前数智技术（如大模型）被深度嵌入情报工作中，带来了效率的飞跃，但也引发了学界对技术可能动摇情报学科根基的忧虑。
    - 存在一个核心矛盾：人工智能模型长于内容生成，而情报工作的根本目标是为支撑决策而循证求真，这导致了技术应用与学科目标的潜在冲突。
    - 业界亟需回答关键问题：大数据和人工智能目前处于何种状态？能否应用？如何应用？其边界何在？
- **创新点**:
    1. **批判性视角**: 不同于多数探讨如何应用 AI 的研究，本文采取了审慎的批判性立场，从根本上反思技术赋能的依据与可靠性，呼吁警惕技术对情报核心价值的侵蚀。
    2. **定义驱动的分析框架**: 将对 AI 的反思建立在作者提出的“情报是人脑做出的有价值的判断”这一核心定义之上，为评估技术的能力与局限性提供了一个统一、自洽的理论视角。
    3. **系统化的反思结构**: 通过“四个反思”构建了清晰的论证结构，分别从情报定义、工作可靠性、数据基础和观点生成机制四个维度，系统地剖析了当前数智技术在情报领域的局限性。

## 4. 详细研究内容
### 4.1 反思1: 数智赋能情报工作的依据是什么?
- 文章指出，情报的定义是情报学和情报工作的逻辑起点，但目前学界存在多达 191 种定义，缺乏共识。
- 这种定义的缺失导致部分情报工作者过度依附技术，忽视了情报本身的价值。
- 作者认为，情报的定义应如同学科定义一样保持稳定和成熟，并提出其沿用多年的工作定义：**情报是人脑做出的有价值的判断**。
    - **核心**: 该定义的核心是“判读”过程。
    - **“判”**: 指界定和筛选数据信息的范围。
    - **“读”**: 指解读与洞察事物现象背后深层次的规律、变化及趋势。
- 基于此，作者认为仅从定义层面难以直接判断数智技术能否应用，因为技术仅是增强了人类的信息获取与整合能力，无法替代人脑进行独立的思考与“判读”。现有所有情报定义都未给技术的替代性应用提供支持。

### 4.2 反思2: 数智赋能情报工作可靠吗?
- 为了验证数智技术在情报工作中的可靠性，作者将情报对象划分为“首次出现”和“再次出现”两种情况进行分析。
- **当情报对象首次出现时**:
    - AI 大模型由于依赖历史数据，对没有先例的实时事件难以准确捕捉和验证。
    - 面对由多个分词构成的新概念时，大模型可能按其固有的算法进行错误的“自动分词”，从而破坏原有语义，生成无关的回答。
    - 相比之下，情报分析人员会从外围关联信息中预判事件的发生（如从异常拥堵预判交通事故），进行主动的征候挖掘和趋势研判。
    - 结论是，人类无法为“未知之未知”提前设计算法，因此面对首次出现的对象，AI 不可能给出完整或正确的分析。
- **当情报对象再次出现时**:
    - 尽管这是大数据的优势领域，但仅在文本上训练的模型学习的是语言形式而非其意义，常生成内容错误的文本。
    - 关键在于，事物发展常伴有非常规的“拐点”，这是人工智能系统无法准确及时推断的。
    - 作者以“统计高中生作息时间”为例，AI 根据历史数据（如 6 月前）会总结出规律的作息，但无法预判该学生在 7 月（暑假）会因场景变化而出现作息“拐点”，而这是人类分析师能轻易发现的。
    - 结论是，AI 的类人脑运算只是表面分析，它将人的经验纳入系统，但无法像人脑一样对非线性问题进行科学判读。

### 4.3 反思3: 现有大数据是否满足大模型算法需要?
- 文章探讨了业界普遍担忧的“数据危机”，即未被使用过的优质数据即将耗尽。
- 耗尽历史数据将动摇大模型的基础。一个看似可行的方案是用模型生成新的合成数据。
- 作者批判了这种方案，认为这无异于将数据在有限范围内多次打包和代入，容易改变数据的精度甚至立场，是一种自我复制，不能真正解决语料问题和对未来的思考。
- 要创造有用的合成数据，必须注入“人性”——即人类文明凝练的智慧和文化底蕴，但这难以达成共识。
- AI 只是通过学习人类语言间接了解外部世界，若没有持续注入全新的真实世界数据，其连“大概反映现实”的能力都将失去。

### 4.4 反思4: 人工智能大模型的观点生成机制可靠吗?
- 文章认为，大模型的本质是统计学，其生成内容的过程如同“随机模仿人类说话的鹦鹉”，缺乏真正的理解。
- 作者以“我饿了”为例：人类说出这句话背后有真实的生理感受（如低血糖），而大模型生成这句话只是基于概率计算，背后没有任何体感和行为链条。
- 因此，具备感觉能力和人脑判断力的 AI 时代远未到来。
- 此外，AI 算法会受训练数据中固有的偏见（如种族、性别歧视）影响，导致其生成的观点出现扭曲。
- 结论是，基于当前统计学的观点生成机制，人工智能的输出并不可靠。

### 4.5 结语
- 人们对 AI 的忧虑是合理的，需要努力平衡技术与人的关系。
- 情报界需反思 AI 的内在机制（基于历史数据总结）和目标（提升情报人员能力），明确自身决策支持的战略定位和以“判读”为核心的工作重点，防止技术喧宾夺主。
- 数智技术拓宽了研究视角、提高了工作效率，但情报界必须回归到一个稳定、成熟的情报定义。
- 只有从明确的定义出发，才能清晰地辨别哪些工作属于情报范畴，哪些体现了情报价值，从而看清 AI 作为权重数字和数学算法的本质。

## 5. 研究结论
- **主要结论**:
    - 数智赋能情报工作缺乏坚实的理论依据，根源在于情报学自身对“情报”这一核心概念缺乏统一、成熟的定义。
    - 数智技术在情报工作中并不可靠，它既无法处理“首次出现”的新事物，也难以把握“再次出现”事物发展过程中的非线性“拐点”。
    - 大模型面临“数据危机”，而已有的数据即将用尽，依靠模型自身生成合成数据的方案无法从根本上解决问题，反而可能引入新的风险。
    - AI 大模型的观点生成机制是基于统计的模仿，缺乏真正的人类理解和判断能力，且其观点易受算法和数据偏见的影响而失真。
- **实践意义**:
    - 情报界应保持警醒，避免技术崇拜，防止技术工具取代情报工作的核心主体地位。
    - 情报工作者应聚焦于发挥人类独有的“判读”能力，即深度解读、洞察和预判，这正是 AI 的短板。
    - 情报机构应坚守其“决策支持”的根本定位，将技术视为提升核心能力的辅助手段，而非工作目标本身。
- **未来工作建议**:
    - 情报学科的当务之急是回归本源，致力于构建一个稳定、成熟、获得共识的“情报”定义。这被认为是辨明情报工作边界、体现情报核心价值、最终驾驭技术挑战的根本前提。