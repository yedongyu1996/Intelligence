 # 科技情报研究领域的大语言模型测评工作思考（2024）

## 1. 研究对象
- **研究领域**: 科技情报研究（S&T Information Research）。
- **核心对象**: 大语言模型（LLMs）在科技情报研究领域的应用测评。研究聚焦于如何构建一套适用于该垂直领域的测评理论框架、测评维度及数据集。
- **数据来源或案例**: 本文为理论性研究，通过归纳和演绎构建理论框架。其分析基于对当前大模型测评现状的总结，参考了包括SuperCLUE、MT-bench等测评基准，以及InfoQ、新华社、斯坦福大学、天津大学等机构发布的通用或行业测评报告。

## 2. 研究方法
- **概念分析与归纳**: 作者首先界定了科技情报研究领域大模型测评的内涵、作用与特殊要求，并通过分析现有测评工作的特点，归纳出面向特定领域测评的必要性。
- **理论框架构建**: 作者设计并提出了两个核心理论模型：
    - **“五维一体”测评总体框架**:
        - **用途**: 为在科技情报领域开展大模型测评工作提供一个系统性、结构化的顶层设计和指导思路。
        - **关键要素**: 框架由测评任务、测评指标、测评数据、测评工具、测评队伍五个相互关联、相互支撑的维度构成。其核心前提是，测评任务是所有其他要素的牵引，决定了测评的方向和目标。
    - **“四维”测评维度与数据集构建框架**:
        - **用途**: 将抽象的测评目标具体化为可衡量、可执行的测评内容，确保测评能够真实反映大模型在情报分析实际工作场景中的能力。
        - **关键要素**: 框架从情报分析人员的视角出发，设立了基础知识能力、动态研究能力、专题研究能力和综合研究能力四个维度。

## 3. 研究出发点与创新性
- **背景与动机**:
    - **技术赋能需求**: 大语言模型已成为赋能各行各业的引擎，其强大的理解和生成能力可为数据密集型的科技情报研究带来颠覆性变革。
    - **领域特殊性**: 科技情报研究工作具有高专业性、高对抗性和高保密性的特点，通用的大模型测评框架无法满足其在数据全面性、专业性、可信性、可追溯性和时效性等方面的特殊要求。
    - **实践紧迫性**: 国内外情报界已高度关注并开始应用生成式人工智能，但缺乏一套科学的评估方法来衡量其应用效果与风险，亟需建立专门的测评体系以确保大模型在该领域的应用质量与安全。
- **创新点**:
    1. 针对“科技情报研究”这一高度专业的垂直领域，首次系统性地提出了大语言模型测评的完整工作思路和方法论。
    2. 独创性地构建了“五维一体”的测评总体框架，将任务、指标、数据、工具、队伍五个关键要素整合成一个有机整体，强调了各要素间的逻辑关系。
    3. 从情报分析人员的实际工作流程和能力需求出发，设计了“基础知识、动态研究、专题研究、综合研究”四位一体的测评维度，使测评内容与领域实践紧密结合，具有很强的应用指导价值。

## 4. 详细研究内容
### 4.1 概述
- **大模型应用情景**: 作者指出，在人工智能的推动下，科技情报研究正经历从“计量”到“计算”的范式革新。大模型的应用能够实现从用户需求提出到产品直接交付的“端到端”服务，重塑情报研究的模式和流程。
- **测评概念与作用**: 针对科技情报领域的LLM测评，其核心是评估模型在该领域的应用能力和效果。其主要作用包括：为研究人员提供客观的模型性能依据；为模型开发者指明优化的方向；通过竞赛和评估推动领域内技术创新。
- **测评重点关注内容**:
    - **全面性**: 要求模型能够基于全量信息资源发现“情报线索”。
    - **专业性**: 考察模型在情报专业知识、分析逻辑和预测推断方面的能力。
    - **可信性**: 关注模型的“幻觉”问题，避免产生虚假信息。
    - **可追溯性**: 确保模型生成内容的来源权威、可靠，线索可追踪。
    - **时效性**: 要求模型能整合最新数据，反映领域的最新动态。
- **测评现状分析**: 文章总结了当前国内外机构的大模型测评工作。研发机构（如InfoQ）侧重综合能力，高校（如斯坦福大学）关注通用性能与安全，第三方机构（如CLUE团队）则进行横向对比。作者指出，虽然已有面向法律、医疗等行业的测评，但尚无针对科技情报领域的系统性测评框架。

### 4.2 科技情报研究领域大模型测评的总体框架
- 作者提出了一个由五个相互关联的要素构成的“五维一体”总体框架，以指导测评工作的开展。
- **测评任务**: 作为框架的核心与牵引，定义了测评需要达成的目标。任务可以从不同视角设定，例如从“任务视角”可设为动态情报研究、综合性情报研究等；从“产品视角”可设为问答系统、研究报告生成等。
- **测评指标**: 作为衡量模型效果的标尺，需要针对不同的测评任务构建个性化、可组合的指标体系，并随着技术发展进行动态更新。
- **测评数据**: 作为决定测评结果可信度的基础，应构建高质量、大规模、多样化的数据集。这包括基础测评集和应用测评集，题型涵盖客观题和主观题，并需建立标准答案库作为评判基准。
- **测评工具**: 作为支撑测评实施的平台环境，应具备测评指标管理、数据集管理、测评流程管理（支持在线自动测评和专家打分）以及测评结果分析等核心功能。
- **测评队伍**: 作为保障测评专业性的重要条件，需要组建一支由情报学、计算机科学、数学、语言学等多学科背景专家和学者构成的专业团队。

### 4.3 科技情报研究领域大模型测评维度及数据集构建
- 该部分从情报研究人员的实际工作能力需求出发，构建了一个四维度的测评框架和相应的数据集构建思路。
- **基础知识能力**:
    - **考察目标**: 衡量模型对情报学基础理论和相关科技领域专业知识的掌握广度与深度。
    - **评测标准**: 准确性、全面性。
    - **数据集构建**: 内容应包括情报基本概念与原理（如信息计量学规律）、分析方法与技术（如SWOT分析），以及跨学科的科技知识（如人工智能、量子科技、生物医学等）。
- **动态研究能力**:
    - **考察目标**: 衡量模型跟踪、研究和掌握全球科技发展动态信息的能力。
    - **评测标准**: 时效性、客观性、完整性、简明性、规范性。
    - **数据集构建**: 可设计将新闻报道改编为动态情报的任务，内容涵盖科技政策、发展战略、组织模式以及太空、海洋、网络空间等具体领域的科技进展。
- **专题研究能力**:
    - **考察目标**: 考察模型围绕特定主题进行深入信息搜集、梳理归纳和分析判断的能力。
    - **评测标准**: 在动态研究能力的基础上，增加针对性、信息性（资料翔实度）、知识性（能否揭示规律）、逻辑性（框架与内容统一）。
    - **数据集构建**: 涵盖政策解读、基本情况介绍、定期/专题综述、专题分析等任务类型，例如分析某项军事条令、综述某领域技术发展历程等。
- **综合研究能力**:
    - **考察目标**: 测试模型在宏观、战略层面进行系统分析，并提出具有决策参考价值的观点、结论和对策的能力。
    - **评测标准**: 在专题研究能力的基础上，增加谋略性、创新性、前瞻性、可行性。
    - **数据集构建**: 包含战略性研究（如分析大国国防科技工业改革）、对策性研究（如探讨保护关键技术的政策建议）、预测性研究（如预判未来军事技术合作前景或技术发展趋势）。

### 4.4 结束语
- 作者总结道，本文通过构建“五维一体”的测评总体框架和“四维”的测评维度与数据集，为科技情报领域的LLM测评工作提供了系统的思路和方法论参考。
- 文章重申，科技情报研究对“实时高效”和“万无一失”有极高要求，这使得专业化、体系化的测评工作尤为重要，是发挥LLM潜能、规避其风险的关键。
- 未来的工作应致力于持续迭代测评指标体系、创新测评方法与工具、加强测评平台和人才队伍建设，从而加速推进大模型在科技情报研究领域的深度、安全应用。

## 5. 研究结论
- **主要结论**:
    - 现有通用大模型测评体系无法满足科技情报研究的特殊需求，必须建立专门的测评框架。
    - 一个有效的测评框架应是“五维一体”的，系统性地整合测评任务、指标、数据、工具和队伍五大要素。
    - 针对科技情报领域的测评内容应围绕“基础知识、动态研究、专题研究、综合研究”四个核心能力维度展开，以确保测评的针对性和实用性。
- **实践意义**:
    - 本研究为科技情报机构、大模型研发企业等相关方开展LLM在情报领域的选型、评估和优化工作提供了理论指导和操作蓝图。
    - 提出的测评维度和数据集构建思路可直接用于开发针对性的测评基准（Benchmark）。
- **未来工作建议**:
    - 持续迭代和优化所提出的测评指标体系，使其更具科学性和可操作性。
    - 积极创新测评工作的方法和模式，例如探索人机结合的测评方式。
    - 加强测评所需的基础条件建设，包括开发标准化的测评工具平台和构建高质量的测评数据集。